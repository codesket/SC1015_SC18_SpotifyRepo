{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af3eb863",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "pd.options.mode.chained_assignment = None # Pretty sure this will come back to stab me in the back\n",
    "%config InlineBackend.figure_format = 'retina' # Higher quality images for slides\n",
    "\n",
    "githubrepo = 'https://raw.githubusercontent.com/joedav98/SC1015_SC18_SpotifyRepo/main/data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd99f4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'converttonumeric' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_27012/2096502009.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     60\u001b[0m   \u001b[0mnonhit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'charted'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m   \u001b[0mnonhit\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'weeks-on-board'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m   \u001b[0mconverttonumeric\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonhit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m   \u001b[0mconvertKeytoCat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnonhit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'converttonumeric' is not defined"
     ]
    }
   ],
   "source": [
    "nonhit0 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_0.csv')\n",
    "nonhit1 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_1.csv')\n",
    "nonhit2 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_2.csv')\n",
    "nonhit3 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_3.csv')\n",
    "nonhit4 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_4.csv')\n",
    "nonhit5 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_5.csv')\n",
    "nonhit6 = pd.read_csv(githubrepo + 'spotify_tracks_metadata_6.csv')\n",
    "\n",
    "\n",
    "nonhit1 = pd.DataFrame(data = nonhit1.values, columns = nonhit0.columns)\n",
    "nonhit2 = pd.DataFrame(data = nonhit2.values, columns = nonhit0.columns)\n",
    "nonhit3 = pd.DataFrame(data = nonhit3.values, columns = nonhit0.columns)\n",
    "nonhit4 = pd.DataFrame(data = nonhit4.values, columns = nonhit0.columns)\n",
    "nonhit5 = pd.DataFrame(data = nonhit5.values, columns = nonhit0.columns)\n",
    "nonhit6 = pd.DataFrame(data = nonhit6.values, columns = nonhit0.columns)\n",
    "\n",
    "\n",
    "nonhitmerge = pd.concat([nonhit0, nonhit1, nonhit2, nonhit3, nonhit4, nonhit5, nonhit6], ignore_index = True).sort_values(by = ['album_release_year'])\n",
    "\n",
    "nonhitpre = nonhitmerge.drop(labels = ['Unnamed: 0',\n",
    "                                        'spotify_id',\n",
    "                                        'album_release_date',\n",
    "                                        'album_release_month',\n",
    "                                        'analysis_url',\n",
    "                                        'mode',\n",
    "                                        'song_explicit',\n",
    "                                        'time_signature',\n",
    "                                        'total_available_markets',\n",
    "                                        'track_href',\n",
    "                                        'uri',\n",
    "                                        'instrumentalness'],\n",
    "                      axis = 1,\n",
    "                      inplace = False)\n",
    "\n",
    "nonhitpre.rename(columns = {'song_name':'track',\n",
    "                            'artist_name':'artist',\n",
    "                            'album_release_year':'year'},\n",
    "               inplace = True) # Renaming columns to merge with larger dataset\n",
    "\n",
    "nonhitprocess = nonhitpre[nonhitpre.song_popularity <= 50].dropna() # Using popularity feature to avoid hit songs\n",
    "nonhitprocess = nonhitprocess.drop(labels = ['song_popularity'], axis = 1, inplace = False)\n",
    "\n",
    "decade90nonhitpre = nonhitprocess[(nonhitprocess.year >= 1990) & (nonhitprocess.year <= 1999)].sort_values(by = ['year'])\n",
    "decade00nonhitpre = nonhitprocess[(nonhitprocess.year >= 2000) & (nonhitprocess.year <= 2009)].sort_values(by = ['year'])\n",
    "decade10nonhitpre1 = nonhitprocess[(nonhitprocess.year >= 2010) & (nonhitprocess.year <= 2018)].sort_values(by = ['year'])\n",
    "decade10nonhitpre2 = nonhitprocess[(nonhitprocess.year == 2019)].sort_values(by = ['year'])\n",
    "decade10nonhitpre3 = nonhitprocess[(nonhitprocess.year == 2020)].sort_values(by = ['year'])\n",
    "decade10nonhitpre4 = nonhitprocess[(nonhitprocess.year == 2021)].sort_values(by = ['year'])\n",
    "\n",
    "decade90nonhit = decade90nonhitpre.sample(n = 2700, random_state = 52)\n",
    "decade00nonhit = decade00nonhitpre.sample(n = 2830, random_state = 52)\n",
    "decade10nonhit1 = decade10nonhitpre1.sample(n = 2570, random_state = 52)\n",
    "decade10nonhit2 = decade10nonhitpre2.sample(n = 480, random_state = 52)\n",
    "decade10nonhit3 = decade10nonhitpre3.sample(n = 450, random_state = 52)\n",
    "decade10nonhit4 = decade10nonhitpre4.sample(n = 500, random_state = 52)\n",
    "\n",
    "decade10nonhit = pd.concat([decade10nonhit1, decade10nonhit2, decade10nonhit3, decade10nonhit4], join = 'inner')\n",
    "\n",
    "for nonhit in [decade90nonhit, decade00nonhit, decade10nonhit]:\n",
    "  nonhit['charted'] = False\n",
    "  nonhit['weeks-on-board'] = 0\n",
    "  converttonumeric(nonhit)\n",
    "  convertKeytoCat(nonhit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c85d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data20s = pd.read_csv(githubrepo + 'dataset-of-20s.csv')\n",
    "data20s = data20s[data20s['Highest Charting Position'] <= 100] # Getting only top 100, instead of top 200\n",
    "drop20s = data20s.drop(labels = ['Index',\n",
    "                                 'Highest Charting Position',\n",
    "                                 'Week of Highest Charting',\n",
    "                                 'Streams',\n",
    "                                 'Artist Followers',\n",
    "                                 'Song ID',\n",
    "                                 'Genre',\n",
    "                                 'Popularity',\n",
    "                                 'Release Date'],\n",
    "                       axis = 1,\n",
    "                       inplace = False) # Dataset of hit songs from 2019 to 2021\n",
    "\n",
    "drop20s['Weeks Charted'] = drop20s['Weeks Charted'].str[:4] # Extracting year of charting from weeks charted\n",
    "\n",
    "drop20s.rename(columns = {'Number of Times Charted':'weeks-on-board',\n",
    "                          'Song Name':'track',\n",
    "                          'Artist':'artist',\n",
    "                          'Weeks Charted':'year',\n",
    "                          'Danceability':'danceability',\n",
    "                          'Energy':'energy',\n",
    "                          'Loudness':'loudness',\n",
    "                          'Speechiness':'speechiness',\n",
    "                          'Acousticness':'acousticness',\n",
    "                          'Liveness':'liveness',\n",
    "                          'Tempo':'tempo',\n",
    "                          'Duration (ms)':'duration_ms',\n",
    "                          'Valence':'valence',\n",
    "                          'Chord':'key'},\n",
    "               inplace = True) # Renaming columns to merge with larger dataset\n",
    "\n",
    "drop20s = drop20s.replace(r'^\\s*$', np.nan, regex=True)\n",
    "drop20s.dropna(subset=['danceability'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b1a555",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Decade 90 NonHits: {len(decade90nonhit.index)}\")\n",
    "print(f\"Decade 00 NonHits: {len(decade00nonhit.index)}\")\n",
    "print(f\"Decade 10 NonHits: {len(decade10nonhit.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc867f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data is uploaded to a github repo, in order to pull when we need\n",
    "data90s = pd.read_csv(githubrepo + 'dataset-of-90s.csv')\n",
    "data00s = pd.read_csv(githubrepo + 'dataset-of-00s.csv')\n",
    "data10s = pd.read_csv(githubrepo + 'dataset-of-10s.csv')\n",
    "charts = pd.read_csv(githubrepo + 'charts.csv').drop_duplicates(subset=['song', 'artist'], keep = 'first') \n",
    "# Dataset from Billboard, drop duplicates leaves only the latest occurence of a hit song\n",
    "\n",
    "datayears = [data90s, data00s, data10s] # Dataset of top tracks from 1960s to 2010s, with Echonest info\n",
    "reference = pd.concat(datayears, ignore_index = True).drop_duplicates(subset = ['track', 'artist'], keep = 'last') # Leaves only latest occurence of a hit song\n",
    "charts['date'] = charts['date'].str[:-6]\n",
    "\n",
    "dropref = reference.drop(labels = ['uri', \n",
    "                                   'mode',\n",
    "                                   'chorus_hit',\n",
    "                                   'sections',\n",
    "                                   'target',\n",
    "                                   'instrumentalness',\n",
    "                                   'time_signature'], \n",
    "                        axis = 1, \n",
    "                        inplace = False) # Dropping features that won't be helpful in analysis\n",
    "\n",
    "dropcharts = charts.drop(labels = ['rank', \n",
    "                                   'last-week',\n",
    "                                   'peak-rank'],\n",
    "                         axis = 1,\n",
    "                         inplace = False).reset_index(drop = True) # Dropping features that won't be helpful in analysis\n",
    "# Rank and peak rank can change in a single year, last week is redundant as we are using the year it charted\n",
    "\n",
    "mergedDF = pd.merge(dropref, dropcharts, left_on = ['track', 'artist'], right_on = ['song', 'artist']) # Merging Spotify data with Billboard data\n",
    "\n",
    "mergedDF = mergedDF.drop(labels = ['song'], axis = 1, inplace = False)\n",
    "mergedDF.rename(columns = {'date':'year'}, inplace = True)\n",
    "\n",
    "mergedDF.year = pd.to_numeric(mergedDF.year)\n",
    "\n",
    "decade90hit = mergedDF[(mergedDF.year >= 1990) & (mergedDF.year <= 1999)]\n",
    "decade00hit = mergedDF[(mergedDF.year >= 2000) & (mergedDF.year <= 2009)]\n",
    "decade10hit = mergedDF[(mergedDF.year >= 2010) & (mergedDF.year <= 2021)]\n",
    "\n",
    "decade10hit = pd.concat([decade10hit, drop20s], join = 'outer').drop_duplicates(subset = ['track', 'artist'], keep = 'last') # Joining the merged dataset with the dataset from 2019 to 2021, defaulting to merged dataset for clashes\n",
    "\n",
    "hits = [decade90hit, decade00hit, decade10hit]\n",
    "for hit in hits:\n",
    "  hit['charted'] = True\n",
    "  converttonumeric(hit)\n",
    "  convertKeytoCat(hit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0a28e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Decade 90 Hits: {len(decade90hit.index)}\")\n",
    "print(f\"Decade 00 Hits: {len(decade00hit.index)}\")\n",
    "print(f\"Decade 10 Hits: {len(decade10hit.index)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cad07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decade90 = pd.concat([decade90hit, decade90nonhit], join = 'inner').reset_index(drop = True)\n",
    "decade00 = pd.concat([decade00hit, decade00nonhit], join = 'inner').reset_index(drop = True)\n",
    "decade10 = pd.concat([decade10hit, decade10nonhit], join = 'inner').reset_index(drop = True)\n",
    "\n",
    "decadeHits = pd.concat([decade90hit,decade00hit,decade10hit], join = 'inner').reset_index(drop = True)\n",
    "decadeNonHits = pd.concat([decade90nonhit,decade00nonhit,decade10nonhit], join = 'inner').reset_index(drop = True)\n",
    "\n",
    "final = pd.concat([decadeHits,decadeNonHits], join = 'inner').reset_index(drop = True)\n",
    "\n",
    "decades = [decade90, decade00, decade10]\n",
    "\n",
    "for decade in decades:\n",
    "  decade.sort_values(by = ['year', 'weeks-on-board']).reset_index(drop = True) # Sorting by year then by weeks-on-board, resetting index as a final preparation of the dataset\n",
    "\n",
    "print(f\"Decade 90s: {len(decade90.index)}\")\n",
    "print(f\"Decade 00s: {len(decade00.index)}\")\n",
    "print(f\"Decade 10s: {len(decade10.index)}\")\n",
    "\n",
    "\n",
    "f, axes = plt.subplots(1, 3, figsize=(28, 4))\n",
    "ax = sb.countplot(x = 'year', data = decade90, ax = axes[0])\n",
    "ax = sb.countplot(x = 'year', data = decade00, ax = axes[1])\n",
    "ax = sb.countplot(x = 'year', data = decade10, ax = axes[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3ff00e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
